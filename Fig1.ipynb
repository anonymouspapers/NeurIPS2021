{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat Task1 and Task2 select models and generate images for Figure 1\n",
    "\n",
    "Note: this uses a modified version of weightwatcher that\n",
    "\n",
    "- prints the images\n",
    "- removes title from the images\n",
    "- adds the log-log histogram of the ESD\n",
    "- removes the ccdf (red lines)\n",
    "\n",
    "#### Note: This NB\n",
    "\n",
    "- needs the data for the specific models listed\n",
    "\n",
    "- used a modified version of WW of 0.4.0.\n",
    "\n",
    "- can in principle be reproduced using ww0.4.1, however, this has not been done yet since Figure 1 is simply illustrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weightwatcher as ww\n",
    "ww.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd starting_kit;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 2\n",
    "if row == 3:\n",
    "    this_task = \"task2_v1\"\n",
    "    repeat_model = 'model_1006'\n",
    "    repeat_layer = 10\n",
    "elif row == 4:\n",
    "    this_task = \"task1_v4\"\n",
    "    repeat_model = 'model_543'\n",
    "    repeat_layer = 7\n",
    "elif row == 2:\n",
    "    this_task = \"task1_v4\"\n",
    "    repeat_model = 'model_152'\n",
    "    repeat_layer = 1\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load ingestion_program/ingestion.py\n",
    "import weightwatcher as ww\n",
    "\n",
    "#=\n",
    "debug_mode = 0\n",
    "\n",
    "# Time budget\n",
    "#############\n",
    "# Maximum time of training in seconds PER MODEL. \n",
    "max_time_per_model = 60 * 5\n",
    "\n",
    "# I/O defaults\n",
    "##############\n",
    "# If true, the previous output directory is not overwritten, it changes name\n",
    "save_previous_results = False\n",
    "# Use default location for the input and output data:\n",
    "# If no arguments to run.py are provided, this is where the data will be found\n",
    "# and the results written to. Change the root_dir to your local directory.\n",
    "root_dir = \"../\"\n",
    "default_input_dir = \"./{}_data\".format(this_task)\n",
    "default_output_dir = \"./{}_out\".format(this_task)\n",
    "default_program_dir = \"ingestion_program\"\n",
    "default_submission_dir = \"./ww_submit_nb\"\n",
    "\n",
    "\n",
    "import os\n",
    "from sys import argv, path\n",
    "import datetime\n",
    "import glob\n",
    "import inspect\n",
    "\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "\n",
    "import tensorflow as tf\n",
    "# enable tf 2.0 behavior\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "filter_filenames = [\".ds_store\", \".DS_Store\", \"__MACOSX\"]\n",
    "verbose = True\n",
    "version = 1\n",
    "\n",
    "# =========================== BEGIN PROGRAM ================================\n",
    "\n",
    "#### Check whether everything went well (no time exceeded)\n",
    "execution_success = True\n",
    "\n",
    "input_dir = default_input_dir\n",
    "output_dir = default_output_dir\n",
    "program_dir= default_program_dir\n",
    "submission_dir= default_submission_dir\n",
    "\n",
    "\n",
    "# Our libraries\n",
    "path.append (program_dir)\n",
    "path.append (submission_dir)\n",
    "\n",
    "import data_io                       # general purpose input/output functions\n",
    "from data_io import vprint           # print only in verbose mode\n",
    "from data_manager import DataManager # load/save data and get info about them\n",
    "#from complexity import complexity # complexity measure\n",
    "\n",
    "#should_pass_submission_dir = 'program_dir' in inspect.getfullargspec(complexity).args\n",
    "\n",
    "if debug_mode >= 4:\n",
    "  print('File structure')\n",
    "  data_io.list_files('..')\n",
    "\n",
    "if debug_mode >= 4: # Show library version and directory structure\n",
    "    data_io.show_dir(\".\")\n",
    "\n",
    "# Move old results and create a new output directory (useful if you run locally)\n",
    "if save_previous_results:\n",
    "    data_io.mvdir(output_dir, output_dir+'_'+the_date) \n",
    "data_io.mkdir(output_dir) \n",
    "\n",
    "#### INVENTORY DATA (and sort dataset names alphabetically)\n",
    "datanames = os.listdir(input_dir)\n",
    "# change input dir to compensate for the single file unzipping\n",
    "if 'input_data' in datanames:\n",
    "    input_dir = os.path.join(input_dir, 'input_data')\n",
    "    datanames = os.listdir(input_dir)\n",
    "# Overwrite the \"natural\" order\n",
    "\n",
    "#### DEBUG MODE: Show dataset list and STOP\n",
    "if debug_mode>=3:\n",
    "    data_io.show_version()\n",
    "    data_io.show_io(input_dir, output_dir)\n",
    "    print('\\n****** Ingestion program version ' + str(version) + ' ******\\n\\n' + '========== DATASETS ==========\\n')        \t\n",
    "    data_io.write_list(datanames)      \n",
    "    datanames = [] # Do not proceed with learning and testing\n",
    "\n",
    "\n",
    "for basename in datanames: # Loop over datasets\n",
    "    if basename in filter_filenames:\n",
    "        continue\n",
    "    vprint( verbose,  \"\\n========== Ingestion program version \" + str(version) + \" ==========\\n\") \n",
    "    vprint( verbose,  \"************************************************\")\n",
    "    vprint( verbose,  \"******** Processing dataset \" + basename.capitalize() + \" ********\")\n",
    "    vprint( verbose,  \"************************************************\")\n",
    "\n",
    "\n",
    "    # ======== Creating a data object with data, informations about it (write a new data manager for loading the models)\n",
    "    vprint(verbose,  \"========= Reading and converting data ==========\")\n",
    "    D = DataManager(basename, input_dir)\n",
    "\n",
    "    training_data = D.load_training_data()\n",
    "    complexity_value = {}\n",
    "    \n",
    "    models = {}\n",
    "    for mid in D.model_ids:\n",
    "        if mid==repeat_model:\n",
    "            #if time_exceeded:\n",
    "            #    complexity_value[mid] = 'EXCEEDED'\n",
    "            #    continue\n",
    "            tf.keras.backend.clear_session()\n",
    "            model = D.load_model(mid)\n",
    "            models[mid]=model\n",
    "            print(\"--------\\nMODEL ID {}\\n--------\\n\".format(mid))\n",
    "\n",
    "    \n",
    "\n",
    "            watcher = ww.WeightWatcher()\n",
    "            results = watcher.analyze(model=model, plot=True, min_size=20, layers=[repeat_layer])\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = \"./paper/img\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!mv ww.esd1.png $IMG_DIR/fig2-2a.png\n",
    "!mv ww.esd2.png $IMG_DIR/fig2-2b.png\n",
    "!mv ww.esd3.png $IMG_DIR/fig2-2c.png\n",
    "!mv ww.esd4.png $IMG_DIR/fig2-2d.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file =  \"{}/fig1-{}a.png\".format(IMG_DIR, row)\n",
    "!mv  ww.esd1.png $file\n",
    "\n",
    "file =  \"{}/fig1-{}b.png\".format(IMG_DIR, row)\n",
    "!mv  ww.esd2.png $file\n",
    "\n",
    "file =  \"{}/fig1-{}c.png\".format(IMG_DIR, row)\n",
    "!mv  ww.esd3.png $file\n",
    "\n",
    "file =  \"{}/fig1-{}d.png\".format(IMG_DIR, row)\n",
    "!mv  ww.esd4.png $file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
